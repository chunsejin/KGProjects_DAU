{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Ch3. Graph Platforms and Processing",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "pycharm-4590281b",
   "language": "python",
   "display_name": "PyCharm (KGProjects)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zc6MgOtzfJIj"
   },
   "source": [
    "# pySpark 설치와 회귀(Regression) 분석해보기\n",
    "본 챕터의 실습에서는 pySpark 3.2 버전을 Colab 내에서 설치하고, 부동산 데이터 셋를 활용하여 부동산 가격에 영향을 미치는 특징을 취합하여 부동산 가격을 예측한다. 또한, 생성된 결과에 대해 통계분석 및 시각화에 대한 간단한 예제를 사용해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wx_VOxbWif8Y"
   },
   "source": [
    "## pySpark import 하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C7Eqb2dnchmq",
    "outputId": "5aa71e2e-a2ac-4954-8023-deacff6668c4",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "!pip install pyspark\n",
    "!apt install openjdk-8-jdk-headless -qq\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sfY7Ko7pcxb-",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# pyspark 모듈 및 sql 라이브러리 설치\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j5pc1BawcysQ",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# create the session\n",
    "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
    "\n",
    "# create the context\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.getOrCreate()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTHAa-DiiM7u"
   },
   "source": [
    "## 스파크 설치 여부 확인"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "S1Ais4ptc0Gn",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "spark"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8V0iYyniPc8"
   },
   "source": [
    "## Spark Web UI로 확인"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QDsFHa46c25J",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip ngrok-stable-linux-amd64.zip\n",
    "get_ipython().system_raw('./ngrok http 4050 &')\n",
    "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4spffq9iTRz"
   },
   "source": [
    "##  데이터셋 올리기\n",
    "BostonHousing.csv 미국 보스톤 부동산 가격정보"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "47wX-Pkad7fm",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "!mkdir data\n",
    "!wget -q https://github.com/chunsejin/KGProjects_DAU/raw/master/data/BostonHousing.csv\n",
    "!mv BostonHousing.csv data\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxfs02jXiaNL"
   },
   "source": [
    "## 회귀분석을 위한 라이브러리 및 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TxogG9gKez8r",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "dataset = spark.read.csv('BostonHousing.csv',inferSchema=True, header =True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZuTRzPJiq1l"
   },
   "source": [
    "## 스키마 출력"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5hAqMpuRe1SJ",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "dataset.printSchema()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PtG2xrLXfpIK",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "dataset.show(10)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6wGFfY3iuO-"
   },
   "source": [
    "## 회귀모델 작성\n",
    "x: 부동산 가격 결정에 영향을 미치는 요인\n",
    "y: 부동산 가격"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zbm9HO3Me3JB",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "#Input all the features in one vector column\n",
    "assembler = VectorAssembler(inputCols=['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat'], outputCol = 'Attributes')\n",
    "\n",
    "output = assembler.transform(dataset)\n",
    "\n",
    "# Input vs Output\n",
    "finalized_data = output.select(\"Attributes\",\"medv\")\n",
    "\n",
    "finalized_data.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ZnIl1GAi-XG"
   },
   "source": [
    "## 회귀모델을 위한 fit 및 예측값 출력\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jNHZwYW_e5nO",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "#Split training and testing data\n",
    "train_data,test_data = finalized_data.randomSplit([0.8,0.2])\n",
    "\n",
    "regressor = LinearRegression(featuresCol = 'Attributes', labelCol = 'medv')\n",
    "\n",
    "#Learn to fit the model from training set\n",
    "regressor = regressor.fit(train_data)\n",
    "\n",
    "#To predict the prices on testing set\n",
    "pred = regressor.evaluate(test_data)\n",
    "\n",
    "#Predict the model\n",
    "pred.predictions.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRQMk3vwsRic"
   },
   "source": [
    "회귀분석의 결정계수(intercept)와 상관계수(coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ukrL_rOde8SP",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "#coefficient of the regression model\n",
    "coeff = regressor.coefficients\n",
    "\n",
    "#X and Y intercept\n",
    "intr = regressor.intercept\n",
    "\n",
    "print (\"The coefficient of the model is : %a\" %coeff)\n",
    "print (\"The Intercept of the model is : %f\" %intr)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hy9pxVnpfFoS"
   },
   "source": [
    "## 기본적인 통계 분석 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Psmf2xfWhoIg",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "x = pred.predictions.select(\"medv\").rdd.flatMap(lambda x: x).collect()\n",
    "y = pred.predictions.select(\"prediction\").rdd.flatMap(lambda x: x).collect()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2t8ah7XXf-Hn",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "#create basic scatterplot\n",
    "plt.plot(x, y, 'o')\n",
    "\n",
    "#obtain m (slope) and b(intercept) of linear regression line\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "\n",
    "#add linear regression line to scatterplot \n",
    "plt.plot(x, m*x+b)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OrhOIN-Pe-EX",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "eval = RegressionEvaluator(labelCol=\"medv\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "# Root Mean Square Error\n",
    "rmse = eval.evaluate(pred.predictions)\n",
    "print(\"RMSE: %.3f\" % rmse)\n",
    "\n",
    "# Mean Square Error\n",
    "mse = eval.evaluate(pred.predictions, {eval.metricName: \"mse\"})\n",
    "print(\"MSE: %.3f\" % mse)\n",
    "\n",
    "# Mean Absolute Error\n",
    "mae = eval.evaluate(pred.predictions, {eval.metricName: \"mae\"})\n",
    "print(\"MAE: %.3f\" % mae)\n",
    "\n",
    "# r2 - coefficient of determination\n",
    "r2 = eval.evaluate(pred.predictions, {eval.metricName: \"r2\"})\n",
    "print(\"r2: %.3f\" %r2)\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}